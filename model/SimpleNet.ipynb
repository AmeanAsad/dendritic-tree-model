{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94441f1f-fa05-4e9d-9de0-8c2336aeffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ [WindowsPath('../data/simulations/sim__saved_InputSpikes_DVTs__1000_outSpikes__128_simulationRuns__6_secDuration__randomSeed_3006033.p')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c5e16fbeb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataLoader import getDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.manual_seed(43)  # for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdefdfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently parsing file: sim__saved_InputSpikes_DVTs__1000_outSpikes__128_simulationRuns__6_secDuration__randomSeed_3006033.p\n",
      "(1, 1278, 768000)\n",
      "Done, time elapsed: 15.524 \n",
      "\n",
      "(1, 1278, 768000)\n",
      "Currently parsing file: sim__saved_InputSpikes_DVTs__1000_outSpikes__128_simulationRuns__6_secDuration__randomSeed_3006033.p\n",
      "(1, 1278, 768000)\n",
      "Done, time elapsed: 23.721 \n",
      "\n",
      "(1, 1278, 768000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data = getDataset()\n",
    "test_data = getDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f770342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64), tensor(-78.6250, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afeb1ef-9cab-41c5-a47e-2dd57cc7359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Helper Functions\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_dl = DataLoader(train_data, BATCH_SIZE, num_workers=0)\n",
    "test_dl = DataLoader(test_data, BATCH_SIZE, num_workers=4)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "train_loader = DeviceDataLoader(train_dl, device)\n",
    "val_loader = DeviceDataLoader(test_dl, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92a8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]], dtype=torch.float64), tensor([-76.9375], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508e42f3-3434-401b-8148-e957ccacf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "class BaseModule(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)\n",
    "        loss = mse_loss(out, labels) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)  \n",
    "        print(out.shape)\n",
    "        print(labels.shape)\n",
    "        loss = mse_loss(out, labels)   \n",
    "        acc = accuracy(out, labels)        \n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def train_val_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)      \n",
    "        loss = mse_loss(out, labels)\n",
    "        acc = accuracy(out, labels)        \n",
    "        return {'train_loss': loss.detach(), 'train_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "       \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch {}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}\".format(epoch + 1, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "\n",
    "    if opt_func == torch.optim.SGD:\n",
    "        optimizer = opt_func(model.parameters(), lr, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "\n",
    "def plotResults(history,name):\n",
    "    losses = [entry['val_loss'] for entry in history]\n",
    "    accuracy = [entry[\"val_acc\"] for entry in history]\n",
    "    train_loss = [entry[\"train_loss\"] for entry in history]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))\n",
    "    fig.suptitle('Model Results')\n",
    "\n",
    "    ax1.plot(losses, '-o', label=\"Validation Loss\")\n",
    "    ax1.plot(train_loss, \"-s\", label=\"Training Loss\")\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim([0,5])\n",
    "    ax1.set(xlabel = 'Epoch', ylabel=\"Loss\")\n",
    "\n",
    "    \n",
    "    ax2.set(xlabel = 'Epoch', ylabel=\"Values\")\n",
    "    ax2.plot(accuracy, \"-r\")\n",
    "\n",
    "    # plt.legend()\n",
    "    ax1.set_title('Loss vs. Number of Epochs');\n",
    "    ax2.set_title(\"Top 1% Accuracy on Validation Set\");\n",
    "    plt.savefig(\"{}-results.png\".format(name))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41d0f5ce-f5c5-45d1-a9a2-581bdb9779d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(BaseModule):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 639 x 250\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 320 x 125\n",
    "    \n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2, 2), # output: 32 x 160 x 63\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 80 x 32\n",
    "    \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(45504, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "    def forward(self, xb):\n",
    "        xb = xb.float()\n",
    "        res = self.net(xb)\n",
    "        return res.to(dtype=torch.float64)\n",
    "\n",
    "# input_shape = (3,1278,500)\n",
    "# summary(SimpleNet(), input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84829109-1a19-4b41-9afa-73fd2fd8edfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1])\n",
      "Epoch 1, Validation Loss: 4666.1703, Validation Accuracy: 0.0000\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1])\n",
      "Epoch 2, Validation Loss: 2684.9415, Validation Accuracy: 0.0000\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1])\n",
      "Epoch 3, Validation Loss: 2854.5619, Validation Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "print(device)\n",
    "model = to_device(SimpleNet(), device)\n",
    "mode = model.to(device)\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.SGD\n",
    "lr = 4e-3\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader)\n",
    "histories.append(history)\n",
    "plotResults(history[1:], \"SimpleNet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d1d319a-3ba0-4a88-8c3f-2928ca5647dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 3            |        cudaMalloc retries: 3         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    2873 MB |    3069 MB |    3667 MB |     793 MB |\\n|       from large pool |    2871 MB |    3067 MB |    3661 MB |     790 MB |\\n|       from small pool |       2 MB |       2 MB |       5 MB |       2 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    2873 MB |    3069 MB |    3667 MB |     793 MB |\\n|       from large pool |    2871 MB |    3067 MB |    3661 MB |     790 MB |\\n|       from small pool |       2 MB |       2 MB |       5 MB |       2 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    2948 MB |    3174 MB |    3174 MB |  231424 KB |\\n|       from large pool |    2944 MB |    3170 MB |    3170 MB |  231424 KB |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   76186 KB |   78785 KB |  474399 KB |  398213 KB |\\n|       from large pool |   74587 KB |   76891 KB |  466022 KB |  391435 KB |\\n|       from small pool |    1599 KB |    2477 KB |    8377 KB |    6777 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |      45    |      51    |     169    |     124    |\\n|       from large pool |       8    |      14    |      51    |      43    |\\n|       from small pool |      37    |      42    |     118    |      81    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |      45    |      51    |     169    |     124    |\\n|       from large pool |       8    |      14    |      51    |      43    |\\n|       from small pool |      37    |      42    |     118    |      81    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       7    |      13    |      13    |       6    |\\n|       from large pool |       5    |      11    |      11    |       6    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       9    |       9    |      68    |      59    |\\n|       from large pool |       4    |       4    |      27    |      23    |\\n|       from small pool |       5    |       5    |      41    |      36    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Net1(BaseModule):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "    \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "    \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(732672, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "          \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        res = self.net(x)\n",
    "        print(res)\n",
    "        return res.to(dtype=torch.float64)\n",
    "\n",
    "torch.cuda.memory_summary(device=device, abbreviated=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7db057-9f77-4fbe-b69e-4011fe5456c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.40 GiB (GPU 0; 6.00 GiB total capacity; 2.81 GiB already allocated; 1.04 GiB free; 2.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12324/930943170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabbreviated\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNet1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12324/331668881.py\u001b[0m in \u001b[0;36mto_device\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuron\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuron\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuron\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuron\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\neuron\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.40 GiB (GPU 0; 6.00 GiB total capacity; 2.81 GiB already allocated; 1.04 GiB free; 2.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "model = to_device(Net1(), device)\n",
    "history = [evaluate(model, val_loader)]\n",
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "history += fit(num_epochs, lr, model, train_loader, val_loader, opt_func)\n",
    "histories.append(history)\n",
    "plotResults(history[1:], \"Net1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
